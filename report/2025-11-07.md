# Daily Report — 2025-11-07
- **Time spent:** ~75 minutes

- **What I set up / built:**
  - Implemented `/ask` API (FastAPI) that retrieves top-k chunks and generates answers.
  - Fixed citation issue by switching to **numbered context** and returning real `sources`.
  - Added minimal **Streamlit** UI (ask box + sources list).
  - Created `/ingest` upload endpoint and UI sidebar to upload PDFs and rebuild index.
  - Added `.gitignore` and a working `Makefile` with proper TABs.
  - Drafted an initial `README.md` (MVP quickstart and structure).

- **Code/modules touched:**
  - `app/api/main.py` (ask route, ingest route, prompt builder)
  - `app/retrieval/retrieve.py` (Retriever class)
  - `app/ui/app.py` (UI + sidebar upload)
  - `.gitignore`, `Makefile`, `README.md`

- **Commands run:**
  - `uvicorn app.api.main:app --reload`
  - `streamlit run app/ui/app.py`
  - `make ingest && make index`
  - `git add . && git commit -m "feat: MVP RAG Copilot" && git push -u origin main`

- **Issues & fixes:**
  - `uvicorn: command not found` → activate `.venv`.
  - Makefile `missing separator` → ensure **TAB** before each recipe.
  - Model output `[DOC:pPAGE]` → replaced with numbered context + real `sources`.

- **Concepts learned:**
  - **Uvicorn** (ASGI server) vs. Gunicorn.
  - Why **FAISS** is needed for fast semantic kNN over chunks.
  - Streamlit file upload → FastAPI `/ingest` → re-index flow.

- **Next:**
  - Add CrossEncoder **reranker**, basic retrieval/E2E eval sample, and small UI polish (confidence + toggleable sources).