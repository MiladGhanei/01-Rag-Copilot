RAG Copilot â€” Evidence-Grounded Q&A (MVP)

A minimal, portfolio-ready RAG app that answers questions over your PDFs with retrieval + citations and a lightweight API + UI. Built to demonstrate practical GenAI skills from the Generative AI with LLMs (DeepLearning.AI + AWS) course.

â¸»

âœ¨ Whatâ€™s included (tonightâ€™s MVP)
	â€¢	PDF â†’ Chunks â†’ Index: pypdf ingestion â†’ JSONL â†’ FAISS vector index.
	â€¢	/ask API: retrieves top-k chunks and generates a concise answer.
	â€¢	Simple UI (Streamlit): ask questions; see answer + sources.
	â€¢	Upload endpoint: ingest new PDFs from the UI and rebuild the index.
	â€¢	Makefile + .gitignore: one-liners and a clean repo.

â¸»

ğŸ§± Minimal architecture

PDFs â”€â”€â–º Ingest (per page JSONL) â”€â”€â–º Embeddings â”€â”€â–º FAISS Index
   UI/API â”€â–º Retrieve top-k chunks â”€â–º LLM prompt â”€â–º Answer + Sources


â¸»

ğŸ§° Tech stack
	â€¢	Python 3.11, FastAPI, Uvicorn, Streamlit
	â€¢	sentence-transformers (embeddings), FAISS-CPU (search)
	â€¢	transformers (LLM; flan-t5-base for CPU-friendly MVP)
	â€¢	pypdf, pydantic, requests, Make

â¸»

ğŸš€ Quickstart

Prereqs
	â€¢	Python 3.11 (recommended), macOS/Homebrew
	â€¢	(Optional) GitHub repo already created

Setup

python3.11 -m venv .venv && source .venv/bin/activate
pip install --upgrade pip
pip install fastapi "uvicorn[standard]" streamlit pypdf sentence-transformers faiss-cpu transformers peft datasets bitsandbytes pydantic requests
mkdir -p data/docs

Add docs & build index

# put a few PDFs into data/docs/
make ingest
make index

Run

# terminal A
make api
# terminal B
make ui

Use
	â€¢	Open Streamlit link; ask a question.
	â€¢	(Optional) Use sidebar to upload a PDF â†’ re-ingest â†’ re-index.
	â€¢	API test:

curl -X POST localhost:8000/ask -H "Content-Type: application/json" \
  -d '{"question":"Summarize page 1."}'


â¸»

ğŸ“ Repo layout

app/
  api/         # FastAPI routes (/ask, /ingest)
  ui/          # Streamlit client
  core/        # config
  retrieval/   # ingest (PDF->JSONL), indexer (FAISS), retriever
  generation/  # (placeholder for advanced prompts/models)
  guardrails/  # (placeholder)
  eval/        # (placeholder for RAG eval)
data/          # docs/, store.jsonl, index.faiss
models/        # (future LoRA adapters)
scripts/       # (future CLI)
report/        # daily logs (_template.md, YYYY-MM-DD.md)


â¸»

ğŸ“ Daily reports
	â€¢	Template: report/_template.md
	â€¢	Example: report/2025-11-03.md (â‰ˆ45 min session: env, ingest, index, API/UI skeleton)

â¸»

ğŸ§ª Whatâ€™s next (planned)
	â€¢	Better retrieval: hybrid BM25 + embeddings, cross-encoder reranking.
	â€¢	RAG eval: RAGAS metrics; small gold Q/A set.
	â€¢	PEFT/LoRA: tune response style & citation behavior.
	â€¢	Docker + CI: reproducible runs, lint/tests, GitHub Actions.
	â€¢	Security & UX: input validation, nicer UI, streaming tokens.

â¸»

ğŸ“š Course â†’ Project (key learnings applied)
	â€¢	Prompting discipline (context-only answers, refusal when unsure).
	â€¢	RAG pipeline: data, retrieval, prompt, generation.
	â€¢	Lifecycle thinking: ingest â†’ index â†’ serve â†’ (evaluate) â†’ iterate.

â¸»

âš–ï¸ License

MIT (proposed). Add your name/year.

â¸»

ğŸ§© Troubleshooting
	â€¢	Makefile â€œmissing separatorâ€ â†’ commands must start with a real TAB.
	â€¢	Empty answers? Ensure data/docs/ has PDFs; rerun make ingest && make index.
	â€¢	Slow first run? Models download on first use (Hugging Face cache).

Polished README (full eval, LoRA, Docker) will be added after the next milestones.